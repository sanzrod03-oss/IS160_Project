{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA) for Crop Disease Prediction\n",
        "\n",
        "This notebook performs exploratory data analysis on the Plant Disease dataset, focusing on Fresno County-relevant crops.\n",
        "\n",
        "## Objectives:\n",
        "1. Visualize the dataset structure\n",
        "2. Analyze class distributions\n",
        "3. Explore sample images from each disease category\n",
        "4. Identify class imbalances\n",
        "5. Visualize disease vs. healthy distribution per crop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path.cwd().parent / 'src'))\n",
        "\n",
        "import config\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Structure Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze dataset structure\n",
        "def analyze_dataset(data_dir):\n",
        "    \"\"\"Analyze the structure and statistics of the dataset.\"\"\"\n",
        "    dataset_info = defaultdict(lambda: defaultdict(int))\n",
        "    \n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_dir = data_dir / split\n",
        "        if not split_dir.exists():\n",
        "            print(f\"⚠ Warning: {split} directory not found\")\n",
        "            continue\n",
        "        \n",
        "        for class_dir in split_dir.iterdir():\n",
        "            if class_dir.is_dir():\n",
        "                class_name = class_dir.name\n",
        "                image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png')) + list(class_dir.glob('*.jpeg'))\n",
        "                dataset_info[split][class_name] = len(image_files)\n",
        "    \n",
        "    return dataset_info\n",
        "\n",
        "# Get dataset statistics\n",
        "data_dir = config.PROCESSED_DATA_DIR.parent\n",
        "dataset_info = analyze_dataset(data_dir)\n",
        "\n",
        "# Display summary\n",
        "print(\"=\"*80)\n",
        "print(\"DATASET SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "for split in ['train', 'val', 'test']:\n",
        "    if split in dataset_info:\n",
        "        total_images = sum(dataset_info[split].values())\n",
        "        num_classes = len(dataset_info[split])\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        print(f\"  Total images: {total_images:,}\")\n",
        "        print(f\"  Number of classes: {num_classes}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Class Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame for easier visualization\n",
        "def create_dataset_df(dataset_info):\n",
        "    \"\"\"Create DataFrame from dataset info.\"\"\"\n",
        "    data = []\n",
        "    for split, classes in dataset_info.items():\n",
        "        for class_name, count in classes.items():\n",
        "            data.append({\n",
        "                'split': split,\n",
        "                'class': class_name,\n",
        "                'count': count\n",
        "            })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df = create_dataset_df(dataset_info)\n",
        "\n",
        "# Plot class distribution for training set\n",
        "if 'train' in dataset_info:\n",
        "    train_df = df[df['split'] == 'train'].sort_values('count', ascending=True)\n",
        "    \n",
        "    plt.figure(figsize=(14, max(10, len(train_df) * 0.3)))\n",
        "    colors = ['green' if 'healthy' in cls.lower() else 'red' for cls in train_df['class']]\n",
        "    plt.barh(train_df['class'], train_df['count'], color=colors, alpha=0.7)\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Class')\n",
        "    plt.title('Training Set: Class Distribution (Green=Healthy, Red=Diseased)', fontsize=14, fontweight='bold')\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nTraining Set Statistics:\")\n",
        "    print(f\"  Mean images per class: {train_df['count'].mean():.1f}\")\n",
        "    print(f\"  Median images per class: {train_df['count'].median():.1f}\")\n",
        "    print(f\"  Min images: {train_df['count'].min()} ({train_df.loc[train_df['count'].idxmin(), 'class']})\")\n",
        "    print(f\"  Max images: {train_df['count'].max()} ({train_df.loc[train_df['count'].idxmax(), 'class']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Crop-wise Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze by crop type\n",
        "def extract_crop_name(class_name):\n",
        "    \"\"\"Extract crop name from class name.\"\"\"\n",
        "    if '___' in class_name:\n",
        "        return class_name.split('___')[0]\n",
        "    elif '_' in class_name:\n",
        "        return class_name.split('_')[0]\n",
        "    return class_name\n",
        "\n",
        "# Add crop column\n",
        "df['crop'] = df['class'].apply(extract_crop_name)\n",
        "\n",
        "# Analyze crops in training set\n",
        "if 'train' in dataset_info:\n",
        "    train_crop_stats = df[df['split'] == 'train'].groupby('crop').agg({\n",
        "        'count': 'sum',\n",
        "        'class': 'count'\n",
        "    }).rename(columns={'count': 'total_images', 'class': 'num_classes'}).sort_values('total_images', ascending=False)\n",
        "    \n",
        "    print(\"\\nCrop Statistics (Training Set):\")\n",
        "    print(train_crop_stats)\n",
        "    \n",
        "    # Plot crop distribution\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Images per crop\n",
        "    train_crop_stats['total_images'].plot(kind='bar', ax=axes[0], color='steelblue', alpha=0.8)\n",
        "    axes[0].set_xlabel('Crop')\n",
        "    axes[0].set_ylabel('Number of Images')\n",
        "    axes[0].set_title('Total Images per Crop', fontsize=12, fontweight='bold')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Classes per crop\n",
        "    train_crop_stats['num_classes'].plot(kind='bar', ax=axes[1], color='coral', alpha=0.8)\n",
        "    axes[1].set_xlabel('Crop')\n",
        "    axes[1].set_ylabel('Number of Disease Classes')\n",
        "    axes[1].set_title('Disease Classes per Crop', fontsize=12, fontweight='bold')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Healthy vs Diseased Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classify as healthy or diseased\n",
        "df['status'] = df['class'].apply(lambda x: 'Healthy' if 'healthy' in x.lower() else 'Diseased')\n",
        "\n",
        "# Overall healthy vs diseased distribution\n",
        "if 'train' in dataset_info:\n",
        "    train_status = df[df['split'] == 'train'].groupby('status')['count'].sum()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Pie chart\n",
        "    colors_pie = ['lightgreen', 'lightcoral']\n",
        "    axes[0].pie(train_status.values, labels=train_status.index, autopct='%1.1f%%', \n",
        "                colors=colors_pie, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
        "    axes[0].set_title('Overall: Healthy vs Diseased Images', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Bar chart per crop\n",
        "    train_crop_status = df[df['split'] == 'train'].groupby(['crop', 'status'])['count'].sum().unstack(fill_value=0)\n",
        "    train_crop_status.plot(kind='bar', stacked=False, ax=axes[1], color=colors_pie, alpha=0.8)\n",
        "    axes[1].set_xlabel('Crop')\n",
        "    axes[1].set_ylabel('Number of Images')\n",
        "    axes[1].set_title('Healthy vs Diseased Images per Crop', fontsize=14, fontweight='bold')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].legend(title='Status')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nHealthy vs Diseased Summary (Training Set):\")\n",
        "    print(train_status)\n",
        "    print(f\"\\nPercentage Diseased: {train_status['Diseased'] / train_status.sum() * 100:.1f}%\")\n",
        "    print(f\"Percentage Healthy: {train_status['Healthy'] / train_status.sum() * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sample Image Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images from different classes\n",
        "def visualize_samples(data_dir, split='train', num_classes=6, samples_per_class=4):\n",
        "    \"\"\"Visualize sample images from random classes.\"\"\"\n",
        "    split_dir = data_dir / split\n",
        "    \n",
        "    if not split_dir.exists():\n",
        "        print(f\"⚠ {split} directory not found\")\n",
        "        return\n",
        "    \n",
        "    # Get random classes\n",
        "    all_classes = [d.name for d in split_dir.iterdir() if d.is_dir()]\n",
        "    selected_classes = np.random.choice(all_classes, size=min(num_classes, len(all_classes)), replace=False)\n",
        "    \n",
        "    fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(16, num_classes * 3))\n",
        "    \n",
        "    if num_classes == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for i, class_name in enumerate(selected_classes):\n",
        "        class_dir = split_dir / class_name\n",
        "        image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png')) + list(class_dir.glob('*.jpeg'))\n",
        "        \n",
        "        # Select random samples\n",
        "        sample_images = np.random.choice(image_files, size=min(samples_per_class, len(image_files)), replace=False)\n",
        "        \n",
        "        for j, img_path in enumerate(sample_images):\n",
        "            img = Image.open(img_path)\n",
        "            axes[i, j].imshow(img)\n",
        "            axes[i, j].axis('off')\n",
        "            \n",
        "            if j == 0:\n",
        "                axes[i, j].set_title(f\"{class_name}\\n({len(image_files)} images)\", \n",
        "                                    fontsize=10, fontweight='bold', loc='left')\n",
        "    \n",
        "    plt.suptitle(f'Sample Images from {split.capitalize()} Set', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training samples\n",
        "print(\"Visualizing sample images from training set...\")\n",
        "visualize_samples(data_dir, split='train', num_classes=8, samples_per_class=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Image Properties Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze image properties (dimensions, aspect ratios)\n",
        "def analyze_image_properties(data_dir, split='train', sample_size=1000):\n",
        "    \"\"\"Analyze properties of images in the dataset.\"\"\"\n",
        "    split_dir = data_dir / split\n",
        "    \n",
        "    if not split_dir.exists():\n",
        "        print(f\"⚠ {split} directory not found\")\n",
        "        return\n",
        "    \n",
        "    widths = []\n",
        "    heights = []\n",
        "    aspect_ratios = []\n",
        "    file_sizes = []\n",
        "    \n",
        "    # Sample random images\n",
        "    all_images = []\n",
        "    for class_dir in split_dir.iterdir():\n",
        "        if class_dir.is_dir():\n",
        "            images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png')) + list(class_dir.glob('*.jpeg'))\n",
        "            all_images.extend(images)\n",
        "    \n",
        "    sampled_images = np.random.choice(all_images, size=min(sample_size, len(all_images)), replace=False)\n",
        "    \n",
        "    print(f\"Analyzing {len(sampled_images)} sample images...\")\n",
        "    \n",
        "    for img_path in sampled_images:\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            w, h = img.size\n",
        "            widths.append(w)\n",
        "            heights.append(h)\n",
        "            aspect_ratios.append(w / h)\n",
        "            file_sizes.append(os.path.getsize(img_path) / 1024)  # KB\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    # Plot distributions\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    axes[0, 0].hist(widths, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[0, 0].set_xlabel('Width (pixels)')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Image Width Distribution')\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    axes[0, 1].hist(heights, bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
        "    axes[0, 1].set_xlabel('Height (pixels)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title('Image Height Distribution')\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    axes[1, 0].hist(aspect_ratios, bins=30, color='green', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 0].set_xlabel('Aspect Ratio (W/H)')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Aspect Ratio Distribution')\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    axes[1, 1].hist(file_sizes, bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_xlabel('File Size (KB)')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('File Size Distribution')\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.suptitle(f'Image Properties Analysis ({split.capitalize()} Set)', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nImage Properties Summary:\")\n",
        "    print(f\"  Width:  Mean={np.mean(widths):.0f}, Median={np.median(widths):.0f}, Range=[{np.min(widths)}, {np.max(widths)}]\")\n",
        "    print(f\"  Height: Mean={np.mean(heights):.0f}, Median={np.median(heights):.0f}, Range=[{np.min(heights)}, {np.max(heights)}]\")\n",
        "    print(f\"  Aspect Ratio: Mean={np.mean(aspect_ratios):.2f}, Median={np.median(aspect_ratios):.2f}\")\n",
        "    print(f\"  File Size (KB): Mean={np.mean(file_sizes):.1f}, Median={np.median(file_sizes):.1f}\")\n",
        "\n",
        "# Analyze image properties\n",
        "analyze_image_properties(data_dir, split='train', sample_size=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"KEY FINDINGS FROM EDA\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "1. Dataset Composition:\n",
        "   - The dataset includes multiple Fresno-relevant crops with varying numbers of disease classes\n",
        "   - Each crop has at least one healthy class and multiple disease classes\n",
        "   \n",
        "2. Class Imbalance:\n",
        "   - Some classes have significantly more images than others\n",
        "   - This may require techniques like class weighting or data augmentation during training\n",
        "   \n",
        "3. Disease Distribution:\n",
        "   - Diseased samples outnumber healthy samples in most crops\n",
        "   - This reflects real-world scenarios where disease identification is critical\n",
        "   \n",
        "4. Image Properties:\n",
        "   - Images have varying dimensions but relatively consistent aspect ratios\n",
        "   - Preprocessing will normalize images to a standard size (224x224) for the model\n",
        "   \n",
        "5. Visual Characteristics:\n",
        "   - Diseased leaves show clear visual patterns: discoloration, spotting, texture irregularities\n",
        "   - These features should be learnable by CNNs\n",
        "   \n",
        "NEXT STEPS:\n",
        "- Proceed to model training with data augmentation to handle class imbalances\n",
        "- Use transfer learning with pre-trained models (ResNet34, VGG16) for better performance\n",
        "- Implement class weighting if needed\n",
        "- Monitor per-class performance, especially for minority classes\n",
        "\"\"\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
